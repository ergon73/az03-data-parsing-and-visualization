#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä —Ü–µ–Ω –Ω–∞ –¥–∏–≤–∞–Ω—ã —Å —Å–∞–π—Ç–∞ divan.ru

–°–∫—Ä–∏–ø—Ç –¥–ª—è —É—á–µ–±–Ω—ã—Ö —Ü–µ–ª–µ–π ‚Äî –¥–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ AZ03.
–°–æ–±–∏—Ä–∞–µ—Ç —Ü–µ–Ω—ã —Å –∫–∞—Ç–∞–ª–æ–≥–∞ –¥–∏–≤–∞–Ω–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ CSV.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/parse_divan.py

–†–µ–∑—É–ª—å—Ç–∞—Ç:
    data/divan_prices_raw.csv
"""

import re
import sys
import time
from pathlib import Path

import requests
from bs4 import BeautifulSoup

# ============================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ‚Äî –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã
# ============================================================

BASE_URL = "https://www.divan.ru/category/divany"
PAGES_TO_FETCH = 2          # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞ (1‚Äì5 –¥–ª—è —É—á–µ–±–Ω—ã—Ö —Ü–µ–ª–µ–π)
REQUEST_DELAY = 1.5         # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)
REQUEST_TIMEOUT = 15        # –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (—Å–µ–∫—É–Ω–¥—ã)

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω –≤–∏–¥–∞ "68 990 —Ä—É–±." –∏–ª–∏ "–æ—Ç 45 990 —Ä—É–±."
PRICE_PATTERN = re.compile(r"\d[\d\s]+—Ä—É–±\.")

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ ‚Äî —É–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ —ç—Ç–æ —É—á–µ–±–Ω—ã–π —Å–∫—Ä–∏–ø—Ç
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 "
        "(AZ03-homework-bot/1.0; educational purposes)"
    ),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
}

# –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
DATA_DIR = Path(__file__).parent.parent / "data"
OUTPUT_FILE = DATA_DIR / "divan_prices_raw.csv"


# ============================================================
# –§–£–ù–ö–¶–ò–ò
# ============================================================

def fetch_page(url: str) -> str | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ URL.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    try:
        response = requests.get(
            url,
            headers=HEADERS,
            timeout=REQUEST_TIMEOUT
        )
        response.raise_for_status()
        return response.text
    except requests.RequestException as e:
        print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}")
        return None


def extract_prices_from_html(html: str) -> list[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å —Ü–µ–Ω–∞–º–∏ –∏–∑ HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç BeautifulSoup –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã,
    –∑–∞—Ç–µ–º –∏—â–µ—Ç –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞ —Ü–µ–Ω—ã.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –≤–∏–¥–∞ "68 990 —Ä—É–±."
    """
    soup = BeautifulSoup(html, "html.parser")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    page_text = soup.get_text(" ", strip=True)
    
    # –ò—â–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º —Ü–µ–Ω—ã
    matches = PRICE_PATTERN.findall(page_text)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
    seen = set()
    unique_prices: list[str] = []
    for price in matches:
        if price not in seen:
            seen.add(price)
            unique_prices.append(price)
    
    return unique_prices


def build_page_url(base_url: str, page: int) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç URL –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞."""
    if page == 1:
        return base_url
    return f"{base_url}?page={page}"


def collect_prices(base_url: str, pages: int, delay: float) -> list[str]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —Ü–µ–Ω—ã —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞.
    
    Args:
        base_url: –ë–∞–∑–æ–≤—ã–π URL –∫–∞—Ç–∞–ª–æ–≥–∞
        pages: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ö–æ–¥–∞
        delay: –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ —Å —Ü–µ–Ω–∞–º–∏
    """
    all_prices: list[str] = []
    
    print(f"\n{'='*50}")
    print(f"–ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω —Å {base_url}")
    print(f"–°—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ö–æ–¥–∞: {pages}")
    print(f"{'='*50}\n")
    
    for page_num in range(1, pages + 1):
        url = build_page_url(base_url, page_num)
        print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{pages}: {url}")
        
        html = fetch_page(url)
        if html is None:
            print(f"  ‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}")
            continue
        
        page_prices = extract_prices_from_html(html)
        print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ü–µ–Ω: {len(page_prices)}")
        
        all_prices.extend(page_prices)
        
        # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
        if page_num < pages:
            print(f"  ‚è≥ –ü–∞—É–∑–∞ {delay} —Å–µ–∫...")
            time.sleep(delay)
    
    print(f"\n{'='*50}")
    print(f"–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ —Ü–µ–Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫: {len(all_prices)}")
    print(f"{'='*50}\n")
    
    return all_prices


def save_to_csv(prices: list[str], output_path: Path) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Ü–µ–Ω –≤ CSV-—Ñ–∞–π–ª.
    
    –§–æ—Ä–º–∞—Ç: –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ "price_raw" —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏ —Ü–µ–Ω.
    """
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º CSV –≤—Ä—É—á–Ω—É—é (–±–µ–∑ pandas –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
    with open(output_path, "w", encoding="utf-8-sig") as f:
        f.write("price_raw\n")
        for price in prices:
            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–∞–≤—ã—á–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
            escaped = price.replace('"', '""')
            f.write(f'"{escaped}"\n')
    
    print(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path.resolve()}")


# ============================================================
# –¢–û–ß–ö–ê –í–•–û–î–ê
# ============================================================

def main() -> int:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    print("\nüõãÔ∏è  –ü–∞—Ä—Å–µ—Ä —Ü–µ–Ω –Ω–∞ –¥–∏–≤–∞–Ω—ã (divan.ru)")
    print("    –£—á–µ–±–Ω—ã–π –ø—Ä–æ–µ–∫—Ç AZ03\n")
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ü–µ–Ω—ã
    prices = collect_prices(
        base_url=BASE_URL,
        pages=PAGES_TO_FETCH,
        delay=REQUEST_DELAY
    )
    
    if not prices:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —Ü–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
        print("   –∏–ª–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ (—Å–∞–π—Ç –º–æ–≥ –∏–∑–º–µ–Ω–∏—Ç—å –≤—ë—Ä—Å—Ç–∫—É).")
        return 1
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    save_to_csv(prices, OUTPUT_FILE)
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –æ—Ç–∫—Ä–æ–π notebooks/az03_homework.ipynb")
    print("   –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤.\n")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
